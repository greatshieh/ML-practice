{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 员工离职预测之特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 目标变量\n",
    "target_var = 'Attrition'\n",
    "\n",
    "# 连续变量\n",
    "num_col = ['Age', 'MonthlyIncome', 'TotalWorkingYears','PercentSalaryHike',\n",
    "           'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "           'YearsWithCurrManager', 'NumCompaniesWorked']\n",
    "# 有序变量\n",
    "ord_col = ['DistanceFromHome', 'StockOptionLevel', 'JobInvolvement',\n",
    "           'PerformanceRating', 'RelationshipSatisfaction',\n",
    "           'WorkLifeBalance']\n",
    "\n",
    "# 分类变量\n",
    "cat_col = ['BusinessTravel', 'Department', 'JobSatisfaction',\n",
    "           'OverTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pandas, numpy, matplotlib, seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy import stats\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "import chimerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../dataset/pfm_modified.csv')\n",
    "df_train['sum'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择\n",
    "<img src='FS1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用卡方检验过滤非连续变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OverTime</th>\n",
       "      <td>1.839919e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <td>2.299846e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobInvolvement</th>\n",
       "      <td>1.050064e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <td>4.375365e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BusinessTravel</th>\n",
       "      <td>4.086993e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Department</th>\n",
       "      <td>2.527176e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <td>3.466896e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <td>1.155587e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PerformanceRating</th>\n",
       "      <td>1.506839e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <td>2.580105e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                pvalue\n",
       "OverTime                  1.839919e-18\n",
       "StockOptionLevel          2.299846e-12\n",
       "JobInvolvement            1.050064e-05\n",
       "JobSatisfaction           4.375365e-04\n",
       "BusinessTravel            4.086993e-03\n",
       "Department                2.527176e-02\n",
       "WorkLifeBalance           3.466896e-02\n",
       "DistanceFromHome          1.155587e-01\n",
       "PerformanceRating         1.506839e-01\n",
       "RelationshipSatisfaction  2.580105e-01"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_result = pd.DataFrame({'pvalue':np.zeros(len(ord_col+cat_col))}, index=ord_col+cat_col)\n",
    "for col in ord_col+cat_col:\n",
    "    freq = df_train.pivot_table(index=col, columns='Attrition', values='sum', aggfunc=sum)\n",
    "    _, p, _, _ = stats.chi2_contingency(freq.values)\n",
    "    chi2_result.loc[col, 'pvalue'] = p\n",
    "chi2_result.sort_values(by='pvalue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "零假设H0: 特征与目标变量独立。显著性水平α=0.05，如果p < alpha，拒绝H0，说明特征变量与目标变量不独立。在chi2_result中过滤p值大于0.05的特征变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取变量:['StockOptionLevel', 'JobInvolvement', 'WorkLifeBalance', 'BusinessTravel', 'Department', 'JobSatisfaction', 'OverTime']\n",
      "与目标独立的变量有：['DistanceFromHome', 'PerformanceRating', 'RelationshipSatisfaction']\n"
     ]
    }
   ],
   "source": [
    "used_cat_col = chi2_result[chi2_result['pvalue']<=0.05].index.tolist()\n",
    "print('提取变量:'+str(used_cat_col))\n",
    "\n",
    "unused_col = [x for x in ord_col+cat_col if x not in used_cat_col]\n",
    "print('与目标独立的变量有：'+str(unused_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对分类变量和有序变量进行卡方检验，删除了**'DistanceFromHome', 'Education', 'PerformanceRating', 'RelationshipSatisfaction', 'TrainingTimesLastYear', 'Gender'**6个变量。<br>\n",
    "从前面的数据探索也可以看出，从这几个变量与目标变量的关系来看，确实没有明显的特征。但是在OverTime上，加班的离职率明显是高于不加班的离职率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用sklearn包的feature_selection过滤变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 卡方检验\n",
    "_, pvalue = chi2(df_train[num_col+ord_col+cat_col], df_train[target_var])\n",
    "chi2_test = pd.Series(pvalue, index=num_col+ord_col+cat_col)\n",
    "\n",
    "# ANVOA（f_classif)\n",
    "_, pvalue = f_classif(df_train[num_col+ord_col+cat_col], df_train[target_var])\n",
    "f_test = pd.Series(pvalue, index=num_col+ord_col+cat_col)\n",
    "\n",
    "# 互信息\n",
    "mi = mutual_info_classif(df_train[num_col+ord_col+cat_col], df_train[target_var])\n",
    "mi_test = pd.Series({'mi':mi}, index=num_col+ord_col+cat_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据处理和预测\n",
    "数据处理部分，为非连续变量创建虚拟变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_processing(result_df=chi2_test, df=df_train, model=LogisticRegression()):\n",
    "    selected_col = result_df[result_df<=0.05].index.tolist()\n",
    "\n",
    "    new_num_col = [x for x in selected_col if x in num_col]\n",
    "    new_cat_col = [x for x in selected_col if x in cat_col]\n",
    "    new_ord_col = [x for x in selected_col if x in ord_col]\n",
    "    \n",
    "    sample_data = df[new_ord_col+new_cat_col+new_num_col].copy()\n",
    "\n",
    "    # 为分类变量和有序变量创建虚拟变量\n",
    "    for col in new_cat_col + new_ord_col:\n",
    "        dummy = pd.get_dummies(sample_data[col], prefix=col)\n",
    "        #onehot_col.extend(dummy.columns.tolist())\n",
    "        sample_data = pd.concat([sample_data, dummy], axis=1)\n",
    "        sample_data.drop([col], axis=1, inplace=True)\n",
    "        \n",
    "    #std_scaler = StandardScaler()\n",
    "    #for col in new_num_col:\n",
    "    # 分割训练集，测试集，70%作为训练集，30%作为测试集\n",
    "    #test_size = 0.3\n",
    "    seed = 45\n",
    "    scoring = 'accuracy'\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #    sample_data,\n",
    "    #    df_train[target_var],\n",
    "    #    test_size=test_size,\n",
    "    #    random_state=seed)\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "    \n",
    "    #lr_model = LogisticRegression(random_state=seed)\n",
    "    model = model.set_params(**({'random_state':seed}))\n",
    "    cv = cross_val_score(cv=kfold, estimator=model, scoring=scoring, X=sample_data, y=df_train[target_var])\n",
    "    #lr_model.fit(X_train, y_train)\n",
    "    #y_pred = lr_model.predict(X_test)\n",
    "    #score = lr_model.score(X_test, y_test)\n",
    "    #print('准确度是: {:0.4f}'.format(score))\n",
    "    print(cv.mean())\n",
    "\n",
    "    return new_ord_col+new_cat_col+new_num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for x in [chi2_test, f_test]:\n",
    "    for z in [LogisticRegression(), RandomForestClassifier(), GradientBoostingClassifier()]:\n",
    "        models.append((x, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856342447535\n",
      "0.839969869786\n",
      "0.85086288123\n",
      "0.865433957728\n",
      "0.852730653923\n",
      "0.861813673557\n"
     ]
    }
   ],
   "source": [
    "for x, z in models:\n",
    "    data_processing(x, df_train, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_col = f_test[f_test<=0.05].index.tolist()\n",
    "\n",
    "new_num_col = [x for x in selected_col if x in num_col]\n",
    "new_cat_col = [x for x in selected_col if x in cat_col]\n",
    "new_ord_col = [x for x in selected_col if x in ord_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'MonthlyIncome',\n",
       " 'TotalWorkingYears',\n",
       " 'YearsAtCompany',\n",
       " 'YearsInCurrentRole',\n",
       " 'YearsSinceLastPromotion',\n",
       " 'YearsWithCurrManager']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistanceFromHome\n",
      "1     0.120909\n",
      "2     0.139091\n",
      "3     0.054545\n",
      "4     0.043636\n",
      "5     0.044545\n",
      "6     0.040909\n",
      "7     0.047273\n",
      "8     0.053636\n",
      "9     0.051818\n",
      "10    0.057273\n",
      "11    0.020000\n",
      "12    0.011818\n",
      "13    0.015455\n",
      "14    0.014545\n",
      "15    0.017273\n",
      "16    0.022727\n",
      "17    0.013636\n",
      "18    0.017273\n",
      "19    0.015455\n",
      "20    0.015455\n",
      "21    0.009091\n",
      "22    0.012727\n",
      "23    0.016364\n",
      "24    0.020909\n",
      "25    0.016364\n",
      "26    0.016364\n",
      "27    0.009091\n",
      "28    0.011818\n",
      "29    0.020909\n",
      "Name: sum, dtype: float64\n",
      "EnvironmentSatisfaction\n",
      "1    0.184545\n",
      "2    0.178182\n",
      "3    0.293636\n",
      "4    0.294545\n",
      "Name: sum, dtype: float64\n",
      "JobInvolvement\n",
      "1    0.052727\n",
      "2    0.239091\n",
      "3    0.572727\n",
      "4    0.086364\n",
      "Name: sum, dtype: float64\n",
      "JobLevel\n",
      "1    0.356364\n",
      "2    0.349091\n",
      "3    0.135455\n",
      "4    0.069091\n",
      "5    0.040909\n",
      "Name: sum, dtype: float64\n",
      "JobSatisfaction\n",
      "1    0.187273\n",
      "2    0.176364\n",
      "3    0.285455\n",
      "4    0.301818\n",
      "Name: sum, dtype: float64\n",
      "RelationshipSatisfaction\n",
      "1    0.187273\n",
      "2    0.190909\n",
      "3    0.292727\n",
      "4    0.280000\n",
      "Name: sum, dtype: float64\n",
      "StockOptionLevel\n",
      "0    0.413636\n",
      "1    0.391818\n",
      "2    0.106364\n",
      "3    0.039091\n",
      "Name: sum, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for col in new_ord_col:\n",
    "    print(df_train.groupby(col)['sum'].sum()/1100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 参考资料\n",
    "- [A Complete Tutorial to Learn Data Science with Python from Scratch](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/)\n",
    "- [Introduction to Feature Selection methods with an example (or how to select the right variables?)](https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
