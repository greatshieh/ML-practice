{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 目标变量\n",
    "target_var = 'Attrition'\n",
    "\n",
    "# 连续变量\n",
    "num_col = ['Age', 'MonthlyIncome', 'TotalWorkingYears','PercentSalaryHike',\n",
    "           'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "           'YearsWithCurrManager', 'NumCompaniesWorked']\n",
    "# 有序变量\n",
    "ord_col = ['DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'JobInvolvement',\n",
    "           'JobLevel', 'JobSatisfaction', 'PerformanceRating', 'RelationshipSatisfaction',\n",
    "           'StockOptionLevel', 'WorkLifeBalance', 'TrainingTimesLastYear']\n",
    "\n",
    "# 分类变量\n",
    "cat_col = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole',\n",
    "           'MaritalStatus', 'OverTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('pfm_train.csv', header=0)\n",
    "test = pd.read_csv('pfm_test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Attrition']\n",
    "X = train.drop([x for x in train.columns if x not in num_col+ord_col+cat_col], axis=1)\n",
    "test = test.drop([x for x in test.columns if x not in num_col+ord_col+cat_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "for col in cat_col:\n",
    "    X[col] = label.fit_transform(X[col])\n",
    "    test[col] = label.transform(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=45)\n",
    "log_reg = LogisticRegression(random_state=45)\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_list = []\n",
    "num_list.append(('X_train', X_train[num_col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连续变量对数变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_log = X_train[num_col].copy()\n",
    "num_log[num_col] = num_log[num_col].apply(lambda x: np.log(1+x))\n",
    "num_list.append(('num_log',num_log))\n",
    "#X_test_log[num_col] = X_test[num_col].apply(lambda x: np.log(1+x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数变换后MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_log_minmax = num_log.copy()\n",
    "scaler = MinMaxScaler()\n",
    "_ = scaler.fit(num_log_minmax)\n",
    "num_log_minmax = scaler.transform(num_log_minmax)\n",
    "num_list.append(('num_log_minmax', num_log_minmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数变换后Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_log_standard = num_log.copy()\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(num_log_standard)\n",
    "num_log_standard = scaler.transform(num_log_standard)\n",
    "num_list.append(('num_log_standard', num_log_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_minmax = X_train[num_col].copy()\n",
    "scaler = MinMaxScaler()\n",
    "_ = scaler.fit(num_minmax)\n",
    "num_minmax = scaler.transform(num_minmax)\n",
    "num_list.append(('num_minmax', num_minmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_standard = X_train[num_col].copy()\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(num_standard)\n",
    "num_standard = scaler.transform(num_standard)\n",
    "num_list.append(('num_standard', num_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理分类变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_list = []\n",
    "cat_list.append(('X_train', X_train[cat_col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类变量dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_dummies = X_train[cat_col].copy()\n",
    "cat_dummies = pd.get_dummies(cat_dummies, columns=cat_col)\n",
    "#X_test = pd.get_dummies(X_test, columns=cat_col)\n",
    "#cat_list.append(('cat_dummies', cat_dummies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy后standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_dummies_standard = cat_dummies.copy()\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(cat_dummies_standard)\n",
    "cat_dummies_standard = scaler.transform(cat_dummies_standard)\n",
    "cat_list.append(('cat_dummies_standard', cat_dummies_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有序变量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_list = []\n",
    "ord_list.append(('X_train', X_train[ord_col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 连续变量对数变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_log = X_train[ord_col].copy()\n",
    "ord_log = ord_log.apply(lambda x: np.log(1+x))\n",
    "ord_list.append(('ord_log',ord_log))\n",
    "#X_test_log[num_col] = X_test[num_col].apply(lambda x: np.log(1+x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数变换后MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_log_minmax = ord_log.copy()\n",
    "scaler = MinMaxScaler()\n",
    "_ = scaler.fit(ord_log_minmax)\n",
    "ord_log_minmax = scaler.transform(ord_log_minmax)\n",
    "ord_list.append(('ord_log_minmax', ord_log_minmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数变换后Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_log_standard = ord_log.copy()\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(ord_log_standard)\n",
    "ord_log_standard = scaler.transform(ord_log_standard)\n",
    "ord_list.append(('ord_log_standard', ord_log_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_minmax = X_train[ord_col].copy()\n",
    "scaler = MinMaxScaler()\n",
    "_ = scaler.fit(ord_minmax)\n",
    "ord_minmax = scaler.transform(ord_minmax)\n",
    "ord_list.append(('ord_minmax', ord_minmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_standard = X_train[ord_col].copy()\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(ord_standard)\n",
    "ord_standard = scaler.transform(ord_standard)\n",
    "ord_list.append(('ord_standard', ord_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类变量dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_dummies = X_train[ord_col].copy()\n",
    "ord_dummies = pd.get_dummies(ord_dummies, columns=ord_col)\n",
    "#X_test = pd.get_dummies(X_test, columns=cat_col)\n",
    "ord_list.append(('ord_dummies', ord_dummies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy后standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ord_dummies_standard = ord_dummies.copy()\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(ord_dummies_standard)\n",
    "ord_dummies_standard = scaler.transform(ord_dummies_standard)\n",
    "ord_list.append(('ord_dummies_standard', ord_dummies_standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X_train[num_col], X_train[ord_col], cat_dummies, y_train], axis=1)\n",
    "# y = y_train\n",
    "predictor = [x for x in data.columns if x != target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-dc690276f9ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%d'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqrt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtlmeanacc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1325\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1326\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1662\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Too many indexers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m                 raise ValueError(\"Location based indexing can only have [%s] \"\n\u001b[0;32m    191\u001b[0m                                  \"types\" % self._valid_types)\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1597\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_is_valid_list_like\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1653\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m         if (hasattr(arr, '__len__') and len(arr) and\n\u001b[1;32m-> 1655\u001b[1;33m                 (arr.max() >= l or arr.min() < -l)):\n\u001b[0m\u001b[0;32m   1656\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# small reductions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "tlmeanacc = 0\n",
    "tlmaxacc = 0\n",
    "i = 1\n",
    "for train, test in kfold.split(X, y):\n",
    "    print('%d'%i)\n",
    "    rf = RandomForestClassifier(random_state=45, max_features='sqrt')\n",
    "    rf.fit(data.iloc[train, predictor], data.iloc[train, target_var])\n",
    "    score = rf.score(data.iloc[test, predictor], data.iloc[test, target_var])\n",
    "    tlmeanacc += score/10\n",
    "    if tlmaxacc <= score:\n",
    "        tlmaxacc = tlmeanacc\n",
    "        feature_importances = pd.DataFrame({'coef':rf.feature_importances_, 'cols':predictor}).sort_values(by='coef', ascending=False)\n",
    "if tlmaxacc <= tlmeanacc:\n",
    "    tlmaxacc = tlmeanacc\n",
    "print(tlmaxacc)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MonthlyIncome',\n",
       " 'Age',\n",
       " 'YearsAtCompany',\n",
       " 'TotalWorkingYears',\n",
       " 'DistanceFromHome',\n",
       " 'OverTime_Yes',\n",
       " 'PercentSalaryHike',\n",
       " 'YearsWithCurrManager',\n",
       " 'JobSatisfaction',\n",
       " 'EnvironmentSatisfaction',\n",
       " 'YearsInCurrentRole',\n",
       " 'YearsSinceLastPromotion',\n",
       " 'RelationshipSatisfaction',\n",
       " 'MaritalStatus_Single',\n",
       " 'Education',\n",
       " 'NumCompaniesWorked',\n",
       " 'TrainingTimesLastYear',\n",
       " 'StockOptionLevel',\n",
       " 'WorkLifeBalance',\n",
       " 'JobInvolvement']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=45, max_features='log2')\n",
    "rf.fit(matrix, y_train)\n",
    "feature_importances = pd.DataFrame({'coef':rf.feature_importances_, 'cols':matrix.columns})\n",
    "feature_importances = feature_importances.sort_values(by='coef', ascending=False)\n",
    "feature_importances['cumsum'] = feature_importances['coef'].cumsum()\n",
    "useful_cols = feature_importances[feature_importances['cumsum']<=0.8]['cols'].tolist()\n",
    "useful_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MonthlyIncome',\n",
       " 'TotalWorkingYears',\n",
       " 'Age',\n",
       " 'DistanceFromHome',\n",
       " 'OverTime_Yes',\n",
       " 'PercentSalaryHike',\n",
       " 'YearsAtCompany',\n",
       " 'YearsWithCurrManager',\n",
       " 'WorkLifeBalance',\n",
       " 'NumCompaniesWorked',\n",
       " 'EnvironmentSatisfaction',\n",
       " 'YearsInCurrentRole']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = matrix[useful_cols]\n",
    "rf.fit(new, y_train)\n",
    "feature_importances = pd.DataFrame({'coef':rf.feature_importances_, 'cols':new.columns})\n",
    "feature_importances = feature_importances.sort_values(by='coef', ascending=False)\n",
    "feature_importances['cumsum'] = feature_importances['coef'].cumsum()\n",
    "useful_cols = feature_importances[feature_importances['cumsum']<=0.8]['cols'].tolist()\n",
    "useful_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MonthlyIncome',\n",
       " 'Age',\n",
       " 'TotalWorkingYears',\n",
       " 'DistanceFromHome',\n",
       " 'OverTime_Yes',\n",
       " 'PercentSalaryHike',\n",
       " 'YearsWithCurrManager',\n",
       " 'EnvironmentSatisfaction']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = matrix[useful_cols]\n",
    "rf.fit(new, y_train)\n",
    "feature_importances = pd.DataFrame({'coef':rf.feature_importances_, 'cols':new.columns})\n",
    "feature_importances = feature_importances.sort_values(by='coef', ascending=False)\n",
    "feature_importances['cumsum'] = feature_importances['coef'].cumsum()\n",
    "useful_cols = feature_importances[feature_importances['cumsum']<=0.8]['cols'].tolist()\n",
    "useful_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=0.845, std=0.015\n",
      "mean=0.847, std=0.015\n",
      "mean=0.851, std=0.017\n",
      "mean=0.847, std=0.016\n",
      "mean=0.845, std=0.015\n",
      "mean=0.842, std=0.014\n",
      "mean=0.844, std=0.019\n",
      "mean=0.849, std=0.018\n",
      "mean=0.845, std=0.011\n",
      "mean=0.840, std=0.015\n",
      "mean=0.848, std=0.016\n",
      "mean=0.849, std=0.018\n",
      "mean=0.844, std=0.020\n",
      "mean=0.853, std=0.016\n",
      "mean=0.842, std=0.014\n",
      "mean=0.845, std=0.017\n",
      "mean=0.847, std=0.019\n",
      "mean=0.853, std=0.012\n",
      "mean=0.842, std=0.018\n",
      "mean=0.839, std=0.020\n",
      "mean=0.848, std=0.021\n",
      "mean=0.838, std=0.024\n",
      "mean=0.840, std=0.031\n",
      "mean=0.846, std=0.030\n",
      "mean=0.782, std=0.038\n",
      "mean=0.814, std=0.030\n",
      "mean=0.824, std=0.033\n",
      "mean=0.823, std=0.039\n",
      "mean=0.835, std=0.044\n",
      "mean=0.819, std=0.029\n",
      "mean=0.823, std=0.043\n",
      "mean=0.834, std=0.039\n",
      "mean=0.818, std=0.022\n",
      "mean=0.798, std=0.028\n",
      "mean=0.822, std=0.046\n",
      "mean=0.828, std=0.034\n",
      "mean=0.828, std=0.044\n",
      "mean=0.830, std=0.041\n",
      "mean=0.821, std=0.025\n",
      "mean=0.785, std=0.030\n",
      "mean=0.812, std=0.030\n",
      "mean=0.822, std=0.025\n",
      "mean=0.823, std=0.041\n",
      "mean=0.846, std=0.020\n",
      "mean=0.842, std=0.020\n",
      "mean=0.844, std=0.036\n",
      "mean=0.855, std=0.026\n",
      "mean=0.851, std=0.026\n",
      "mean=0.801, std=0.039\n",
      "mean=0.816, std=0.028\n",
      "mean=0.824, std=0.033\n",
      "mean=0.842, std=0.031\n",
      "mean=0.845, std=0.026\n",
      "mean=0.819, std=0.019\n",
      "mean=0.847, std=0.029\n",
      "mean=0.851, std=0.028\n",
      "mean=0.817, std=0.012\n",
      "mean=0.806, std=0.037\n",
      "mean=0.827, std=0.035\n",
      "mean=0.802, std=0.026\n",
      "mean=0.845, std=0.030\n",
      "mean=0.855, std=0.030\n",
      "mean=0.820, std=0.018\n",
      "mean=0.804, std=0.029\n",
      "mean=0.820, std=0.039\n",
      "mean=0.808, std=0.026\n",
      "mean=0.829, std=0.038\n",
      "mean=0.865, std=0.022\n",
      "mean=0.848, std=0.018\n",
      "mean=0.839, std=0.045\n",
      "mean=0.849, std=0.033\n",
      "mean=0.850, std=0.022\n",
      "mean=0.793, std=0.028\n",
      "mean=0.819, std=0.029\n",
      "mean=0.829, std=0.037\n",
      "mean=0.800, std=0.035\n",
      "mean=0.833, std=0.028\n",
      "mean=0.838, std=0.019\n",
      "mean=0.825, std=0.035\n",
      "mean=0.839, std=0.025\n",
      "mean=0.828, std=0.012\n",
      "mean=0.802, std=0.027\n",
      "mean=0.831, std=0.041\n",
      "mean=0.822, std=0.025\n",
      "mean=0.822, std=0.036\n",
      "mean=0.823, std=0.029\n",
      "mean=0.829, std=0.020\n",
      "mean=0.795, std=0.024\n",
      "mean=0.827, std=0.036\n",
      "mean=0.830, std=0.028\n",
      "mean=0.815, std=0.028\n",
      "mean=0.844, std=0.022\n",
      "mean=0.842, std=0.022\n",
      "mean=0.842, std=0.029\n",
      "mean=0.853, std=0.025\n",
      "mean=0.862, std=0.019\n",
      "mean=0.807, std=0.036\n",
      "mean=0.827, std=0.028\n",
      "mean=0.811, std=0.032\n",
      "mean=0.845, std=0.026\n",
      "mean=0.844, std=0.024\n",
      "mean=0.816, std=0.016\n",
      "mean=0.853, std=0.030\n",
      "mean=0.846, std=0.024\n",
      "mean=0.816, std=0.010\n",
      "mean=0.807, std=0.028\n",
      "mean=0.825, std=0.029\n",
      "mean=0.805, std=0.022\n",
      "mean=0.850, std=0.035\n",
      "mean=0.845, std=0.031\n",
      "mean=0.816, std=0.021\n",
      "mean=0.814, std=0.031\n",
      "mean=0.822, std=0.030\n",
      "mean=0.802, std=0.036\n",
      "mean=0.830, std=0.039\n",
      "mean=0.856, std=0.021\n",
      "mean=0.842, std=0.024\n",
      "mean=0.832, std=0.042\n",
      "mean=0.847, std=0.032\n",
      "mean=0.847, std=0.022\n",
      "mean=0.791, std=0.028\n",
      "mean=0.824, std=0.032\n",
      "mean=0.820, std=0.044\n",
      "mean=0.813, std=0.029\n",
      "mean=0.840, std=0.024\n",
      "mean=0.823, std=0.022\n",
      "mean=0.819, std=0.042\n",
      "mean=0.841, std=0.024\n",
      "mean=0.814, std=0.022\n",
      "mean=0.806, std=0.031\n",
      "mean=0.822, std=0.029\n",
      "mean=0.833, std=0.020\n",
      "mean=0.823, std=0.038\n",
      "mean=0.832, std=0.029\n",
      "mean=0.813, std=0.028\n",
      "mean=0.797, std=0.030\n",
      "mean=0.824, std=0.029\n",
      "mean=0.825, std=0.025\n",
      "mean=0.828, std=0.032\n",
      "mean=0.848, std=0.029\n",
      "mean=0.846, std=0.020\n",
      "mean=0.835, std=0.038\n",
      "mean=0.853, std=0.027\n",
      "mean=0.861, std=0.017\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(columns=['name', 'mean', 'std'])\n",
    "poly = PolynomialFeatures(2)\n",
    "for num_name, num_values in num_list:\n",
    "    for ord_name, ord_values in ord_list:\n",
    "        for cat_name, cat_values in cat_list:\n",
    "            feature = '{}+{}+{}'.format(num_name, ord_name, cat_name)\n",
    "            matrix = np.hstack((num_values, ord_values, cat_values))\n",
    "            new = poly.fit_transform(matrix)\n",
    "            score = cross_val_score(estimator=log_reg, cv=kfold, X=new, y=y_train)\n",
    "            print('mean={:.3f}, std={:.3f}'.format(np.mean(score), np.std(score)))\n",
    "            result.loc[len(result)] = [feature, np.mean(score), np.std(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = np.hstack((num_log_minmax,ord_dummies,cat_dummies))\n",
    "new = poly.fit_transform(matrix)\n",
    "for i in range(1, new.shape[1]+1):\n",
    "    rfe = RFE(estimator=log_reg, n_features_to_select=i)\n",
    "    cv_score = cross_val_score(estimator=rfe, cv=kfold, X=new, y=y_train)\n",
    "#     _ = rfe.fit(opt_train, y_train)\n",
    "#     score = rfe.score(opt_test, y_test)\n",
    "    print('%d: CV result:%.3f'%(i, np.mean(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>num_log_minmax+ord_dummies+cat_dummies</td>\n",
       "      <td>0.865420</td>\n",
       "      <td>0.022198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>num_log_standard+ord_dummies_standard+cat_dumm...</td>\n",
       "      <td>0.861776</td>\n",
       "      <td>0.019151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>num_standard+ord_dummies_standard+cat_dummies_...</td>\n",
       "      <td>0.860615</td>\n",
       "      <td>0.017167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>num_minmax+ord_dummies+cat_dummies</td>\n",
       "      <td>0.855737</td>\n",
       "      <td>0.021308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>num_log_minmax+ord_minmax+cat_dummies</td>\n",
       "      <td>0.854604</td>\n",
       "      <td>0.029944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>num_log+ord_dummies_standard+cat_dummies</td>\n",
       "      <td>0.854532</td>\n",
       "      <td>0.025510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X_train+ord_minmax+cat_dummies</td>\n",
       "      <td>0.853443</td>\n",
       "      <td>0.016438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>X_train+ord_standard+cat_dummies_standard</td>\n",
       "      <td>0.853428</td>\n",
       "      <td>0.012484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>num_log_standard+ord_dummies_standard+cat_dummies</td>\n",
       "      <td>0.853370</td>\n",
       "      <td>0.024871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>num_standard+ord_dummies_standard+cat_dummies</td>\n",
       "      <td>0.853356</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>num_minmax+ord_log_minmax+X_train</td>\n",
       "      <td>0.853298</td>\n",
       "      <td>0.030166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>num_log+ord_dummies_standard+cat_dummies_standard</td>\n",
       "      <td>0.850989</td>\n",
       "      <td>0.026183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train+X_train+cat_dummies_standard</td>\n",
       "      <td>0.850975</td>\n",
       "      <td>0.016521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>num_log_minmax+ord_log_minmax+cat_dummies</td>\n",
       "      <td>0.850960</td>\n",
       "      <td>0.028019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>num_log_minmax+ord_dummies_standard+cat_dummie...</td>\n",
       "      <td>0.849770</td>\n",
       "      <td>0.021825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>num_minmax+ord_minmax+X_train</td>\n",
       "      <td>0.849668</td>\n",
       "      <td>0.034646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>num_log_minmax+ord_dummies_standard+cat_dummies</td>\n",
       "      <td>0.848608</td>\n",
       "      <td>0.032876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X_train+ord_log_minmax+cat_dummies</td>\n",
       "      <td>0.848594</td>\n",
       "      <td>0.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X_train+ord_log_standard+cat_dummies_standard</td>\n",
       "      <td>0.848521</td>\n",
       "      <td>0.017882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>num_log_minmax+ord_dummies+cat_dummies_standard</td>\n",
       "      <td>0.848493</td>\n",
       "      <td>0.018059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>X_train+ord_dummies+cat_dummies_standard</td>\n",
       "      <td>0.848493</td>\n",
       "      <td>0.021164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X_train+ord_log_standard+cat_dummies</td>\n",
       "      <td>0.848478</td>\n",
       "      <td>0.015648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>num_standard+ord_dummies+cat_dummies</td>\n",
       "      <td>0.848419</td>\n",
       "      <td>0.028697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>num_minmax+ord_dummies_standard+cat_dummies</td>\n",
       "      <td>0.847403</td>\n",
       "      <td>0.031928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train+X_train+cat_dummies</td>\n",
       "      <td>0.847345</td>\n",
       "      <td>0.014729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train+ord_log+X_train</td>\n",
       "      <td>0.847345</td>\n",
       "      <td>0.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>num_minmax+ord_dummies_standard+cat_dummies_st...</td>\n",
       "      <td>0.847331</td>\n",
       "      <td>0.021935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X_train+ord_standard+cat_dummies</td>\n",
       "      <td>0.847302</td>\n",
       "      <td>0.019365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>num_log_minmax+ord_log_minmax+X_train</td>\n",
       "      <td>0.847229</td>\n",
       "      <td>0.029116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>num_log+ord_dummies+cat_dummies</td>\n",
       "      <td>0.846227</td>\n",
       "      <td>0.020190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>num_minmax+ord_minmax+cat_dummies_standard</td>\n",
       "      <td>0.815784</td>\n",
       "      <td>0.021275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>num_minmax+ord_log_minmax+cat_dummies_standard</td>\n",
       "      <td>0.815769</td>\n",
       "      <td>0.010238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>num_log_minmax+X_train+cat_dummies</td>\n",
       "      <td>0.815740</td>\n",
       "      <td>0.028226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>num_log_standard+ord_dummies+X_train</td>\n",
       "      <td>0.814535</td>\n",
       "      <td>0.028464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>num_standard+ord_log_minmax+cat_dummies_standard</td>\n",
       "      <td>0.814491</td>\n",
       "      <td>0.022180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>num_log+X_train+cat_dummies</td>\n",
       "      <td>0.814477</td>\n",
       "      <td>0.029712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>num_minmax+ord_standard+X_train</td>\n",
       "      <td>0.814404</td>\n",
       "      <td>0.030956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>num_standard+ord_log+X_train</td>\n",
       "      <td>0.813373</td>\n",
       "      <td>0.029482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>num_standard+ord_minmax+cat_dummies_standard</td>\n",
       "      <td>0.813316</td>\n",
       "      <td>0.027950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>num_log+ord_standard+cat_dummies</td>\n",
       "      <td>0.812067</td>\n",
       "      <td>0.030245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>num_minmax+X_train+cat_dummies_standard</td>\n",
       "      <td>0.810891</td>\n",
       "      <td>0.032395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>num_log_minmax+ord_standard+cat_dummies_standard</td>\n",
       "      <td>0.808380</td>\n",
       "      <td>0.026069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>num_minmax+X_train+X_train</td>\n",
       "      <td>0.807319</td>\n",
       "      <td>0.036014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>num_minmax+ord_log_standard+X_train</td>\n",
       "      <td>0.807131</td>\n",
       "      <td>0.028299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>num_standard+ord_log_standard+X_train</td>\n",
       "      <td>0.805998</td>\n",
       "      <td>0.030505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>num_log_minmax+ord_log_standard+X_train</td>\n",
       "      <td>0.805795</td>\n",
       "      <td>0.037129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>num_minmax+ord_log_standard+cat_dummies_standard</td>\n",
       "      <td>0.804750</td>\n",
       "      <td>0.022148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>num_log_minmax+ord_standard+X_train</td>\n",
       "      <td>0.803531</td>\n",
       "      <td>0.028806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>num_log_minmax+ord_log_standard+cat_dummies_st...</td>\n",
       "      <td>0.802340</td>\n",
       "      <td>0.026141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>num_log_standard+ord_log_standard+X_train</td>\n",
       "      <td>0.802325</td>\n",
       "      <td>0.027277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>num_minmax+ord_standard+cat_dummies_standard</td>\n",
       "      <td>0.802282</td>\n",
       "      <td>0.036318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>num_log_minmax+X_train+X_train</td>\n",
       "      <td>0.801164</td>\n",
       "      <td>0.039213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>num_log_standard+ord_log+X_train</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>0.035382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>num_log+ord_log_standard+X_train</td>\n",
       "      <td>0.797505</td>\n",
       "      <td>0.027577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>num_standard+ord_standard+X_train</td>\n",
       "      <td>0.797462</td>\n",
       "      <td>0.030410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>num_log_standard+ord_standard+X_train</td>\n",
       "      <td>0.795037</td>\n",
       "      <td>0.024203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>num_log_standard+X_train+X_train</td>\n",
       "      <td>0.792743</td>\n",
       "      <td>0.028044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>num_standard+X_train+X_train</td>\n",
       "      <td>0.791451</td>\n",
       "      <td>0.028365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>num_log+ord_standard+X_train</td>\n",
       "      <td>0.785368</td>\n",
       "      <td>0.029729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>num_log+X_train+X_train</td>\n",
       "      <td>0.781797</td>\n",
       "      <td>0.038385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name      mean       std\n",
       "67              num_log_minmax+ord_dummies+cat_dummies  0.865420  0.022198\n",
       "95   num_log_standard+ord_dummies_standard+cat_dumm...  0.861776  0.019151\n",
       "143  num_standard+ord_dummies_standard+cat_dummies_...  0.860615  0.017167\n",
       "115                 num_minmax+ord_dummies+cat_dummies  0.855737  0.021308\n",
       "61               num_log_minmax+ord_minmax+cat_dummies  0.854604  0.029944\n",
       "46            num_log+ord_dummies_standard+cat_dummies  0.854532  0.025510\n",
       "13                      X_train+ord_minmax+cat_dummies  0.853443  0.016438\n",
       "17           X_train+ord_standard+cat_dummies_standard  0.853428  0.012484\n",
       "94   num_log_standard+ord_dummies_standard+cat_dummies  0.853370  0.024871\n",
       "142      num_standard+ord_dummies_standard+cat_dummies  0.853356  0.027100\n",
       "102                  num_minmax+ord_log_minmax+X_train  0.853298  0.030166\n",
       "47   num_log+ord_dummies_standard+cat_dummies_standard  0.850989  0.026183\n",
       "2                 X_train+X_train+cat_dummies_standard  0.850975  0.016521\n",
       "55           num_log_minmax+ord_log_minmax+cat_dummies  0.850960  0.028019\n",
       "71   num_log_minmax+ord_dummies_standard+cat_dummie...  0.849770  0.021825\n",
       "108                      num_minmax+ord_minmax+X_train  0.849668  0.034646\n",
       "70     num_log_minmax+ord_dummies_standard+cat_dummies  0.848608  0.032876\n",
       "7                   X_train+ord_log_minmax+cat_dummies  0.848594  0.017985\n",
       "11       X_train+ord_log_standard+cat_dummies_standard  0.848521  0.017882\n",
       "68     num_log_minmax+ord_dummies+cat_dummies_standard  0.848493  0.018059\n",
       "20            X_train+ord_dummies+cat_dummies_standard  0.848493  0.021164\n",
       "10                X_train+ord_log_standard+cat_dummies  0.848478  0.015648\n",
       "139               num_standard+ord_dummies+cat_dummies  0.848419  0.028697\n",
       "118        num_minmax+ord_dummies_standard+cat_dummies  0.847403  0.031928\n",
       "1                          X_train+X_train+cat_dummies  0.847345  0.014729\n",
       "3                              X_train+ord_log+X_train  0.847345  0.015662\n",
       "119  num_minmax+ord_dummies_standard+cat_dummies_st...  0.847331  0.021935\n",
       "16                    X_train+ord_standard+cat_dummies  0.847302  0.019365\n",
       "54               num_log_minmax+ord_log_minmax+X_train  0.847229  0.029116\n",
       "43                     num_log+ord_dummies+cat_dummies  0.846227  0.020190\n",
       "..                                                 ...       ...       ...\n",
       "110         num_minmax+ord_minmax+cat_dummies_standard  0.815784  0.021275\n",
       "104     num_minmax+ord_log_minmax+cat_dummies_standard  0.815769  0.010238\n",
       "49                  num_log_minmax+X_train+cat_dummies  0.815740  0.028226\n",
       "90                num_log_standard+ord_dummies+X_train  0.814535  0.028464\n",
       "128   num_standard+ord_log_minmax+cat_dummies_standard  0.814491  0.022180\n",
       "25                         num_log+X_train+cat_dummies  0.814477  0.029712\n",
       "111                    num_minmax+ord_standard+X_train  0.814404  0.030956\n",
       "123                       num_standard+ord_log+X_train  0.813373  0.029482\n",
       "134       num_standard+ord_minmax+cat_dummies_standard  0.813316  0.027950\n",
       "40                    num_log+ord_standard+cat_dummies  0.812067  0.030245\n",
       "98             num_minmax+X_train+cat_dummies_standard  0.810891  0.032395\n",
       "65    num_log_minmax+ord_standard+cat_dummies_standard  0.808380  0.026069\n",
       "96                          num_minmax+X_train+X_train  0.807319  0.036014\n",
       "105                num_minmax+ord_log_standard+X_train  0.807131  0.028299\n",
       "129              num_standard+ord_log_standard+X_train  0.805998  0.030505\n",
       "57             num_log_minmax+ord_log_standard+X_train  0.805795  0.037129\n",
       "107   num_minmax+ord_log_standard+cat_dummies_standard  0.804750  0.022148\n",
       "63                 num_log_minmax+ord_standard+X_train  0.803531  0.028806\n",
       "59   num_log_minmax+ord_log_standard+cat_dummies_st...  0.802340  0.026141\n",
       "81           num_log_standard+ord_log_standard+X_train  0.802325  0.027277\n",
       "113       num_minmax+ord_standard+cat_dummies_standard  0.802282  0.036318\n",
       "48                      num_log_minmax+X_train+X_train  0.801164  0.039213\n",
       "75                    num_log_standard+ord_log+X_train  0.799900  0.035382\n",
       "33                    num_log+ord_log_standard+X_train  0.797505  0.027577\n",
       "135                  num_standard+ord_standard+X_train  0.797462  0.030410\n",
       "87               num_log_standard+ord_standard+X_train  0.795037  0.024203\n",
       "72                    num_log_standard+X_train+X_train  0.792743  0.028044\n",
       "120                       num_standard+X_train+X_train  0.791451  0.028365\n",
       "39                        num_log+ord_standard+X_train  0.785368  0.029729\n",
       "24                             num_log+X_train+X_train  0.781797  0.038385\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_train = X_train.copy()\n",
    "opt_test = X_test.copy()\n",
    "\n",
    "opt_train[num_col+ord_col] = opt_train[num_col+ord_col].apply(lambda x: np.log(1+x))\n",
    "opt_test[num_col+ord_col] = opt_test[num_col+ord_col].apply(lambda x: np.log(1+x))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(opt_train[num_col+ord_col])\n",
    "opt_train[num_col+ord_col] = scaler.transform(opt_train[num_col+ord_col])\n",
    "opt_test[num_col+ord_col] = scaler.transform(opt_test[num_col+ord_col])\n",
    "\n",
    "opt_train = pd.get_dummies(opt_train, columns=cat_col)\n",
    "opt_test = pd.get_dummies(opt_test, columns=cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: CV result:0.839, test result:0.836\n",
      "2: CV result:0.839, test result:0.836\n",
      "3: CV result:0.838, test result:0.836\n",
      "4: CV result:0.838, test result:0.840\n",
      "5: CV result:0.838, test result:0.840\n",
      "6: CV result:0.834, test result:0.855\n",
      "7: CV result:0.830, test result:0.858\n",
      "8: CV result:0.840, test result:0.858\n",
      "9: CV result:0.845, test result:0.858\n",
      "10: CV result:0.845, test result:0.862\n",
      "11: CV result:0.850, test result:0.865\n",
      "12: CV result:0.856, test result:0.862\n",
      "13: CV result:0.853, test result:0.869\n",
      "14: CV result:0.849, test result:0.869\n",
      "15: CV result:0.851, test result:0.873\n",
      "16: CV result:0.857, test result:0.880\n",
      "17: CV result:0.861, test result:0.876\n",
      "18: CV result:0.858, test result:0.884\n",
      "19: CV result:0.859, test result:0.880\n",
      "20: CV result:0.869, test result:0.876\n",
      "21: CV result:0.864, test result:0.869\n",
      "22: CV result:0.869, test result:0.869\n",
      "23: CV result:0.874, test result:0.876\n",
      "24: CV result:0.874, test result:0.873\n",
      "25: CV result:0.875, test result:0.869\n",
      "26: CV result:0.880, test result:0.876\n",
      "27: CV result:0.876, test result:0.869\n",
      "28: CV result:0.875, test result:0.884\n",
      "29: CV result:0.881, test result:0.887\n",
      "30: CV result:0.880, test result:0.887\n",
      "31: CV result:0.884, test result:0.876\n",
      "32: CV result:0.888, test result:0.876\n",
      "33: CV result:0.888, test result:0.876\n",
      "34: CV result:0.887, test result:0.876\n",
      "35: CV result:0.891, test result:0.876\n",
      "36: CV result:0.891, test result:0.876\n",
      "37: CV result:0.890, test result:0.876\n",
      "38: CV result:0.887, test result:0.876\n",
      "39: CV result:0.887, test result:0.880\n",
      "40: CV result:0.887, test result:0.876\n",
      "41: CV result:0.887, test result:0.873\n",
      "42: CV result:0.890, test result:0.873\n",
      "43: CV result:0.888, test result:0.873\n",
      "44: CV result:0.890, test result:0.873\n",
      "45: CV result:0.890, test result:0.873\n",
      "46: CV result:0.888, test result:0.873\n",
      "47: CV result:0.888, test result:0.873\n",
      "48: CV result:0.888, test result:0.873\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, opt_train.shape[1]+1):\n",
    "    rfe = RFE(estimator=log_reg, n_features_to_select=i)\n",
    "    cv_score = cross_val_score(estimator=rfe, cv=kfold, X=opt_train, y=y_train)\n",
    "    _ = rfe.fit(opt_train, y_train)\n",
    "    score = rfe.score(opt_test, y_test)\n",
    "    print('%d: CV result:%.3f, test result:%.3f'%(i, np.mean(cv_score), score))\n",
    "#   pipe = make_pipeline(rfe, log_reg)\n",
    "#     score = cross_val_score(estimator=pipe, cv=kfold, X=opt_train, y=y_train)\n",
    "#     print('mean={:.3f}, std={:.3f}'.format(np.mean(score), np.std(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.870, std=0.022\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(estimator=log_reg, cv=kfold, X=X, y=y)\n",
    "print('mean: {:.3f}, std={:.3f}'.format(np.mean(score), np.std(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[num_col] = X[num_col].apply(lambda x: np.log(1+x))\n",
    "test[num_col] = test[num_col].apply(lambda x: np.log(1+x))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(X[num_col+ord_col])\n",
    "X[num_col+ord_col] = scaler.transform(X[num_col+ord_col])\n",
    "test[num_col+ord_col] = scaler.transform(test[num_col+ord_col])\n",
    "\n",
    "X = pd.get_dummies(X, columns=cat_col)\n",
    "test = pd.get_dummies(test, columns=cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.888, std=0.023\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(estimator=log_reg, cv=kfold, X=X, y=y)\n",
    "print('mean: {:.3f}, std={:.3f}'.format(np.mean(score), np.std(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n",
      "{'C': 0.5, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "params = {'penalty': ['l1', 'l2'], 'C':[.5, 1, 1.5]}\n",
    "grid = GridSearchCV(estimator=log_reg, param_grid=params, cv=kfold)\n",
    "_ = grid.fit(opt_train, y_train)\n",
    "print(grid.score(opt_test, y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.891, std=0.022\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(estimator=LogisticRegression(C=0.5, random_state=45), cv=kfold, X=X, y=y)\n",
    "print('mean: {:.3f}, std={:.3f}'.format(np.mean(score), np.std(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=0.5, random_state=45)\n",
    "clf.fit(X, y)\n",
    "pred = clf.predict(test).astype(int)\n",
    "result = pd.DataFrame({'result':pred})\n",
    "result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
